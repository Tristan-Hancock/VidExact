{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Mixed precision policy set to: <Policy \"mixed_float16\">\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Limit TF to grow GPU memory as needed (optional but recommended)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"{len(gpus)} GPU(s) found. Memory growth enabled.\")\n",
    "\n",
    "# Enable mixed precision for faster training on RTX 4070\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "print(\"Mixed precision policy set to:\", mixed_precision.global_policy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, numpy as np\n",
    "\n",
    "# Path to the UCF-101 dataset directory (update this to your actual path)\n",
    "data_dir = r\"C:\\Users\\acer\\OneDrive\\Documents\\Dev Work\\AI\\ProjectX\\ProjectX\\UCF-101\"\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "\n",
    "# List all action classes\n",
    "class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {num_classes} classes.\")  # Expect 101 for full UCF-101\n",
    "\n",
    "# Gather all video file paths and their class labels\n",
    "video_paths, labels = [], []\n",
    "video_paths = []\n",
    "labels = []\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.endswith(\".avi\"):\n",
    "            video_paths.append(os.path.join(class_dir, file))\n",
    "            labels.append(label)\n",
    "print(f\"Found {len(video_paths)} videos.\")\n",
    "\n",
    "# Define parameters for frame extraction\n",
    "FRAMES_PER_VIDEO = 16\n",
    "IMG_HEIGHT, IMG_WIDTH = 112, 112\n",
    "\n",
    "def extract_frames_from_video(video_path, num_frames=FRAMES_PER_VIDEO):\n",
    "    \"\"\"Read a video file and extract `num_frames` frames, resized to IMG_HEIGHT x IMG_WIDTH.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total_frames <= 0:\n",
    "        cap.release()\n",
    "        return None  # unable to read video\n",
    "    # Determine frame indices to sample (evenly spaced)\n",
    "    interval = max(total_frames // num_frames, 1)\n",
    "    for i in range(num_frames):\n",
    "        frame_index = int(i * interval)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # end of video\n",
    "        # Resize frame to target size and normalize pixel values\n",
    "        frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        frame = frame.astype(\"float32\") / 255.0  # normalize to [0,1]\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    # If video is shorter than num_frames, pad with black frames\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=\"float32\"))\n",
    "    return np.array(frames)  # shape: (num_frames, IMG_HEIGHT, IMG_WIDTH, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split into train and test sets (80/20 split)\n",
    "random_indices = np.random.permutation(len(video_paths))\n",
    "split_idx = int(0.8 * len(video_paths))\n",
    "train_idx, test_idx = random_indices[:split_idx], random_indices[split_idx:]\n",
    "train_videos = [video_paths[i] for i in train_idx]\n",
    "train_labels = [labels[i] for i in train_idx]\n",
    "test_videos  = [video_paths[i] for i in test_idx]\n",
    "test_labels  = [labels[i] for i in test_idx]\n",
    "print(f\"Training videos: {len(train_videos)}, Testing videos: {len(test_videos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, tensorflow as tf\n",
    "\n",
    "def frame_generator(video_list, label_list, training=False):\n",
    "    \"\"\"Generator that yields (frames, label) for each video in the list.\"\"\"\n",
    "    indices = list(range(len(video_list)))\n",
    "    if training:\n",
    "        random.shuffle(indices)  # shuffle order each epoch for training\n",
    "    for idx in indices:\n",
    "        frames = extract_frames_from_video(video_list[idx], FRAMES_PER_VIDEO)\n",
    "        if frames is None:\n",
    "            continue  # skip unreadable video\n",
    "        # Data augmentation: random horizontal flip for training data\n",
    "        if training and random.random() < 0.5:\n",
    "            frames = np.flip(frames, axis=2)  # flip frames horizontally\n",
    "        yield frames, label_list[idx]\n",
    "\n",
    "# Create tf.data Datasets for training and testing\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: frame_generator(train_videos, train_labels, training=True),\n",
    "    output_signature=(tf.TensorSpec(shape=(FRAMES_PER_VIDEO, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),\n",
    "                      tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    ")\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: frame_generator(test_videos, test_labels, training=False),\n",
    "    output_signature=(tf.TensorSpec(shape=(FRAMES_PER_VIDEO, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),\n",
    "                      tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    ")\n",
    "\n",
    "# Batch and prefetch the datasets for performance\n",
    "BATCH_SIZE = 8\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Inspect one batch of training data\n",
    "for frames_batch, labels_batch in train_ds.take(1):\n",
    "    print(\"Batch frames shape:\", frames_batch.shape)\n",
    "    print(\"Batch labels:\", labels_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, BatchNormalization, Flatten, Dense, Dropout\n",
    "\n",
    "# Define model parameters\n",
    "FRAMES_PER_VIDEO = 16\n",
    "IMG_HEIGHT, IMG_WIDTH = 112, 112\n",
    "num_classes = 101  # For UCF-101\n",
    "\n",
    "model = Sequential([\n",
    "    # First Conv3D: Pool only spatially to preserve temporal dimension.\n",
    "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding='same',\n",
    "           input_shape=(FRAMES_PER_VIDEO, IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling3D(pool_size=(1, 2, 2)),  # Temporal dimension remains 16\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Second Conv3D: now pool in all dimensions\n",
    "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),  # Temporal: 16/2 = 8\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Third Conv3D: pool in all dimensions\n",
    "    Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),  # Temporal: 8/2 = 4\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "for frames_batch, labels_batch in train_ds.take(1):\n",
    "    print(\"Frames shape:\", frames_batch.shape)\n",
    "    print(\"Labels shape:\", labels_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(train_ds, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(..., metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ucf101_3dcnn.h5\")\n",
    "# This creates a file 'ucf101_3dcnn.h5' with the model.\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(\"ucf101_3dcnn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have a new video file \"new_video.mp4\" that we want to classify\n",
    "new_video_path = \"new_video.mp4\"\n",
    "frames = extract_frames_from_video(new_video_path, num_frames=FRAMES_PER_VIDEO)\n",
    "if frames is None:\n",
    "    print(\"Could not read video or video too short.\")\n",
    "else:\n",
    "    frames = np.expand_dims(frames, axis=0)  # shape becomes (1, num_frames, H, W, 3)\n",
    "    predictions = loaded_model.predict(frames)  # model expects batch input\n",
    "    predicted_label = np.argmax(predictions[0])\n",
    "    print(\"Predicted action:\", class_names[predicted_label])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
